{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "237b54c7-15d4-45b0-afec-ff5ed49b6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from meta_ood.meta_ood_master.config import config_evaluation_setup\n",
    "from meta_ood.meta_ood_master.src.imageaugmentations import Compose, Normalize, ToTensor\n",
    "# from meta_ood.meta_ood_master.src.model_utils import inference\n",
    "from scipy.stats import entropy\n",
    "# from meta_ood.meta_ood_master.src.calc import calc_precision_recall, calc_sensitivity_specificity\n",
    "from meta_ood.meta_ood_master.src.helper import concatenate_metrics\n",
    "from meta_ood.meta_ood_master.meta_classification import meta_classification\n",
    "from meta_ood.meta_ood_master.UNet import ResNetUNet, convrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0937c91-5639-4868-b2b4-f0aaff9c73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eval_pixels(object):\n",
    "    \"\"\"\n",
    "    Evaluate in vs. out separability on pixel-level\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, roots, dataset):\n",
    "        self.params = params\n",
    "        self.epoch = params.val_epoch\n",
    "        self.alpha = params.pareto_alpha\n",
    "        self.batch_size = params.batch_size\n",
    "        self.roots = roots\n",
    "        self.dataset = dataset\n",
    "        self.save_dir_data = os.path.join(self.roots.io_root, \"results/entropy_counts_per_pixel\")\n",
    "        self.save_dir_plot = os.path.join(self.roots.io_root, \"plots\")\n",
    "        print(\"Save dir of plots: {}\".format(self.save_dir_plot))\n",
    "        if self.epoch == 0:\n",
    "            self.pattern = \"baseline\"\n",
    "            self.save_path_data = os.path.join(self.save_dir_data, \"baseline.p\")\n",
    "        else:\n",
    "            self.pattern = \"epoch_\" + str(self.epoch) + \"_alpha_\" + str(self.alpha)\n",
    "            self.save_path_data = os.path.join(self.save_dir_data, self.pattern + \".p\")\n",
    "\n",
    "    def counts(self, loader, num_bins=100, save_path=None, rewrite=False):\n",
    "        \"\"\"\n",
    "        Count the number in-distribution and out-distribution pixels\n",
    "        and get the networks corresponding confidence scores\n",
    "        :param loader: dataset loader for evaluation data\n",
    "        :param num_bins: (int) number of bins for histogram construction\n",
    "        :param save_path: (str) path where to save the counts data\n",
    "        :param rewrite: (bool) whether to rewrite the data file if already exists\n",
    "        \"\"\"\n",
    "        print(\"\\nCounting in-distribution and out-distribution pixels\")\n",
    "        if save_path is None:\n",
    "            save_path = self.save_path_data\n",
    "        if not os.path.exists(save_path) or rewrite:\n",
    "            save_dir = os.path.dirname(save_path)\n",
    "            if not os.path.exists(save_dir):\n",
    "                print(\"Create directory\", save_dir)\n",
    "                os.makedirs(save_dir)\n",
    "            bins = np.linspace(start=0, stop=1, num=num_bins + 1)\n",
    "            counts = {\"in\": np.zeros(num_bins, dtype=\"int64\"), \"out\": np.zeros(num_bins, dtype=\"int64\")}\n",
    "            inf = inference(self.params, self.roots, loader, self.dataset.num_eval_classes)\n",
    "            print(inf.model_name)\n",
    "            for i in range(len(loader)):\n",
    "                probs, gt_train, _, _ = inf.probs_gt_load(i)\n",
    "                ent = entropy(probs, axis=0) / np.log(self.dataset.num_eval_classes)\n",
    "                counts[\"in\"] += np.histogram(ent[gt_train == self.dataset.train_id_in], bins=bins, density=False)[0]\n",
    "                counts[\"out\"] += np.histogram(ent[gt_train == self.dataset.train_id_out], bins=bins, density=False)[0]\n",
    "                print(\"\\rImages Processed: {}/{}\".format(i + 1, len(loader)), end=' ')\n",
    "                sys.stdout.flush()\n",
    "            torch.cuda.empty_cache()\n",
    "            pickle.dump(counts, open(save_path, \"wb\"))\n",
    "        print(\"Counts data saved:\", save_path)\n",
    "\n",
    "    def oodd_metrics_pixel(self, datloader=None, load_path=None):\n",
    "        \"\"\"\n",
    "        Calculate 3 OoD detection metrics, namely AUROC, FPR95, AUPRC\n",
    "        :param datloader: dataset loader\n",
    "        :param load_path: (str) path to counts data (run 'counts' first)\n",
    "        :return: OoD detection metrics\n",
    "        \"\"\"\n",
    "        if load_path is None:\n",
    "            load_path = self.save_path_data\n",
    "        if not os.path.exists(load_path):\n",
    "            if datloader is None:\n",
    "                print(\"Please, specify dataset loader\")\n",
    "                exit()\n",
    "            self.counts(loader=datloader, save_path=load_path)\n",
    "        print(\"Load Path: {}\".format(load_path))\n",
    "        data = pickle.load(open(load_path, \"rb\"))\n",
    "        fpr, tpr, _, auroc = calc_sensitivity_specificity(data, balance=True)\n",
    "        fpr95 = fpr[(np.abs(tpr - 0.95)).argmin()]\n",
    "        _, _, _, auprc = calc_precision_recall(data)\n",
    "        if self.epoch == 0:\n",
    "            print(\"\\nOoDD Metrics - Epoch %d - Baseline\" % self.epoch)\n",
    "        else:\n",
    "            print(\"\\nOoDD Metrics - Epoch %d - Lambda %.2f\" % (self.epoch, self.alpha))\n",
    "        print(\"AUROC:\", auroc)\n",
    "        print(\"FPR95:\", fpr95)\n",
    "        print(\"AUPRC:\", auprc)\n",
    "        return auroc, fpr95, auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b98479b-9d87-4f22-90a9-61fef9e3a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "class inference(object):\n",
    "\n",
    "    def __init__(self, params, roots, loader, num_classes=None, init_net=True):\n",
    "        self.epoch = params.val_epoch\n",
    "        self.alpha = params.pareto_alpha\n",
    "        self.batch_size = params.batch_size\n",
    "        self.model_name = roots.model_name\n",
    "        print(self.model_name)\n",
    "        self.batch = 0\n",
    "        self.batch_max = int(len(loader) / self.batch_size) + (len(loader) % self.batch_size > 0)\n",
    "        self.loader = loader\n",
    "        self.batchloader = iter(DataLoader(loader, batch_size=self.batch_size, shuffle=False))\n",
    "        self.probs_root = os.path.join(roots.io_root, \"probs\")\n",
    "\n",
    "        if self.epoch == 0:\n",
    "            pattern = \"baseline\"\n",
    "            ckpt_path = roots.init_ckpt\n",
    "            self.probs_load_dir = os.path.join(self.probs_root, pattern)\n",
    "        else:\n",
    "            pattern = \"epoch_\" + str(self.epoch) + \"_alpha_\" + str(self.alpha)\n",
    "            basename = self.model_name + \"_\" + pattern + \".pth\"\n",
    "            self.probs_load_dir = os.path.join(self.probs_root, pattern)\n",
    "            ckpt_path = os.path.join(roots.weights_dir, basename)\n",
    "        if init_net and num_classes is not None:\n",
    "            # self.net = load_network(self.model_name, num_classes, ckpt_path)\n",
    "            \n",
    "            UNet_trained = ResNetUNet(19)\n",
    "            UNet_untrained = ResNetUNet(19)\n",
    "\n",
    "            checkpoint_path_trained=\"/work/pi_noah_daniels_uri_edu/said_harb_uri_edu_data/io/ood_detection/meta_ood_UNetResNet/weights/UNetResNet_epoch_76_alpha_0.9.pth\"\n",
    "            checkpoint_path_untrained=\"/work/pi_noah_daniels_uri_edu/said_harb_uri_edu_data/io/ood_detection/meta_ood_UNetResNet/weights/UNetResNet.pth\"\n",
    "\n",
    "            state_dict_trained=torch.load(checkpoint_path_trained)['state_dict']\n",
    "            UNet_trained.load_state_dict(state_dict_trained)\n",
    "\n",
    "            state_dict_untrained=torch.load(checkpoint_path_untrained)\n",
    "            UNet_untrained.load_state_dict(state_dict_untrained)\n",
    "            self.net=UNet_trained\n",
    "            \n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.net=self.net.to(device)\n",
    "\n",
    "    def probs_gt_load(self, i, load_dir=None):\n",
    "        if load_dir is None:\n",
    "            load_dir = self.probs_load_dir\n",
    "            print(\"Load Directory is None!\")\n",
    "        try:\n",
    "            print(\"We are in the try of probs_gt_load\")\n",
    "            filename = os.path.join(load_dir, \"probs\" + str(i) + \".hdf5\")\n",
    "            print(filename)\n",
    "            f_probs = h5py.File(filename, \"r\")\n",
    "            probs = np.asarray(f_probs['probabilities'])\n",
    "            gt_train = np.asarray(f_probs['gt_train_ids'])\n",
    "            gt_label = np.asarray(f_probs['gt_label_ids'])\n",
    "            probs = np.squeeze(probs)\n",
    "            gt_train = np.squeeze(gt_train)\n",
    "            gt_label = np.squeeze(gt_label)\n",
    "            im_path = f_probs['image_path'][0].decode(\"utf8\")\n",
    "        except OSError:\n",
    "            print(\"No probs file for image %d, therefore run inference...\" % i)\n",
    "            probs, gt_train, gt_label, im_path = self.prob_gt_calc(i)\n",
    "        return probs, gt_train, gt_label, im_path\n",
    "\n",
    "    def probs_gt_save(self, i, save_dir=None):\n",
    "        if save_dir is None:\n",
    "            save_dir = self.probs_load_dir\n",
    "        if not os.path.exists(save_dir):\n",
    "            print(\"Create directory:\", save_dir)\n",
    "            os.makedirs(save_dir)\n",
    "        probs, gt_train, gt_label, im_path = self.prob_gt_calc(i)\n",
    "        file_name = os.path.join(save_dir, \"probs\" + str(i) + \".hdf5\")\n",
    "        f = h5py.File(file_name, \"w\")\n",
    "        f.create_dataset(\"probabilities\", data=probs)\n",
    "        f.create_dataset(\"gt_train_ids\", data=gt_train)\n",
    "        f.create_dataset(\"gt_label_ids\", data=gt_label)\n",
    "        f.create_dataset(\"image_path\", data=[im_path.encode('utf8')])\n",
    "        print(\"file stored:\", file_name)\n",
    "        f.close()\n",
    "\n",
    "    def probs_gt_load_batch(self):\n",
    "        assert self.batch_size > 1, \"Please use batch size > 1 or use function 'probs_gt_load()' instead, bye bye...\"\n",
    "        x, y, z, im_paths = next(self.batchloader)\n",
    "        print(x.shape)\n",
    "        probs = prediction(self.net, x)\n",
    "        gt_train = y.numpy()\n",
    "        gt_label = z.numpy()\n",
    "        self.batch += 1\n",
    "        print(\"\\rBatch %d/%d processed\" % (self.batch, self.batch_max))\n",
    "        sys.stdout.flush()\n",
    "        return probs, gt_train, gt_label, im_paths\n",
    "\n",
    "    def prob_gt_calc(self, i):\n",
    "        x, y = self.loader[i]\n",
    "        print(x.shape)\n",
    "        probs = np.squeeze(prediction(self.net, x.unsqueeze_(0)))\n",
    "        gt_train = y.numpy()\n",
    "        try:\n",
    "            gt_label = np.array(Image.open(self.loader.annotations[i]).convert('L'))\n",
    "            print(\"Try Successful\")\n",
    "        except AttributeError:\n",
    "            gt_label = np.zeros(gt_train.shape)\n",
    "        im_path = self.loader.images[i]\n",
    "        return probs, gt_train, gt_label, im_path\n",
    "\n",
    "def prediction(net, image):\n",
    "    image = image.cuda()\n",
    "    with torch.no_grad():\n",
    "        out = net(image)\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "    out = out.data.cpu()\n",
    "    out = F.softmax(out, 1)\n",
    "    return out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22e0a697-df1a-4335-bbbc-e6b26019f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_ood.meta_ood_master.src.helper import counts_array_to_data_list\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score, auc\n",
    "def calc_precision_recall(data, balance=False):\n",
    "    if balance:\n",
    "        x1 = counts_array_to_data_list(np.array(data[\"in\"]), 1e+5)\n",
    "        x2 = counts_array_to_data_list(np.array(data[\"out\"]), 1e+5)\n",
    "    else:\n",
    "        ratio_in = np.sum(data[\"in\"]) / (np.sum(data[\"in\"]) + np.sum(data[\"out\"]))\n",
    "        ratio_out = 1 - ratio_in\n",
    "        x1 = counts_array_to_data_list(np.array(data[\"in\"]), 1e+7 * ratio_in)\n",
    "        x2 = counts_array_to_data_list(np.array(data[\"out\"]), 1e+7 * ratio_out)\n",
    "    probas_pred1 = np.array(x1) / 100\n",
    "    probas_pred2 = np.array(x2) / 100\n",
    "    y_true = np.concatenate((np.zeros(len(probas_pred1)), np.ones(len(probas_pred2))))\n",
    "    y_scores = np.concatenate((probas_pred1, probas_pred2))\n",
    "    return precision_recall_curve(y_true, y_scores) + (average_precision_score(y_true, y_scores), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db92a312-9ddc-4db1-8209-74e63c4be4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sensitivity_specificity(data, balance=False):\n",
    "    if balance:\n",
    "        x1 = counts_array_to_data_list(np.array(data[\"in\"]), max_size=1e+5)\n",
    "        x2 = counts_array_to_data_list(np.array(data[\"out\"]), max_size=1e+5)\n",
    "    else:\n",
    "        x1 = counts_array_to_data_list(np.array(data[\"in\"]))\n",
    "        x2 = counts_array_to_data_list(np.array(data[\"out\"]))\n",
    "    probas_pred1 = np.array(x1) / 100\n",
    "    probas_pred2 = np.array(x2) / 100\n",
    "    y_true = np.concatenate((np.zeros(len(probas_pred1)), np.ones(len(probas_pred2)))).astype(\"uint8\")\n",
    "    y_scores = np.concatenate((probas_pred1, probas_pred2))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    return fpr, tpr, thresholds, auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9509e74-362b-4648-a1eb-2d3c3afa5c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATE MODEL:  UNetResNet\n",
      "\n",
      "PIXEL-LEVEL EVALUATION\n",
      "Save dir of plots: /work/pi_noah_daniels_uri_edu/said_harb_uri_edu_data/io/ood_detection/meta_ood_UNetResNet/fs_eval/plots\n",
      "Load Path: /work/pi_noah_daniels_uri_edu/said_harb_uri_edu_data/io/ood_detection/meta_ood_UNetResNet/fs_eval/results/entropy_counts_per_pixel/epoch_76_alpha_0.9.p\n",
      "\n",
      "OoDD Metrics - Epoch 76 - Lambda 0.90\n",
      "AUROC: 0.8773581436648372\n",
      "FPR95: 0.3853149511765647\n",
      "AUPRC: 0.1906332271956456\n",
      "\n",
      "FINISHED 00:00:04.79\n"
     ]
    }
   ],
   "source": [
    "args={\"TRAINSET\":\"Cityscapes+COCO\",\n",
    "      \"VALSET\":\"Fishyscapes\",\n",
    "      \"MODEL\": \"UNetResNet\",# UNetResNet\n",
    "      \"val_epoch\": 76,\n",
    "      \"pareto_alpha\": 0.9,\n",
    "      \"pixel_eval\":True,\n",
    "      \"segment_eval\":False}\n",
    "\n",
    "config = config_evaluation_setup(args)\n",
    "if not args[\"pixel_eval\"] and not args[\"segment_eval\"]:\n",
    "    args[\"pixel_eval\"] = args[\"segment_eval\"] = True\n",
    "\n",
    "transform = Compose([ToTensor(), Normalize(config.dataset.mean, config.dataset.std)])\n",
    "datloader = config.dataset(root=config.roots.eval_dataset_root, transform=transform)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\"\"\"Perform evaluation\"\"\"\n",
    "print(\"\\nEVALUATE MODEL: \", config.roots.model_name)\n",
    "if args[\"pixel_eval\"]:\n",
    "    print(\"\\nPIXEL-LEVEL EVALUATION\")\n",
    "    eval_pixels(config.params, config.roots, config.dataset).oodd_metrics_pixel(datloader=datloader)\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end - start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nFINISHED {:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(minutes), seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e605bc-62e0-4d80-b027-35a8833290eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba5684-2c1f-47ef-ac04-66957a7cfaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
